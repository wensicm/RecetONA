{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c088ea0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path('/home/wencm/Alimentación')\n",
        "REQ_PATH = BASE_DIR / 'requirements.txt'\n",
        "LIB_DIR = BASE_DIR / 'lib'\n",
        "LIB_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "subprocess.check_call([\n",
        "    sys.executable,\n",
        "    '-m',\n",
        "    'pip',\n",
        "    'install',\n",
        "    '--upgrade',\n",
        "    '--target',\n",
        "    str(LIB_DIR),\n",
        "    '-r',\n",
        "    str(REQ_PATH),\n",
        "])\n",
        "\n",
        "print(f'Requirements instalados en: {LIB_DIR}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ce49d4",
      "metadata": {},
      "source": [
        "# Mercadona RAG Notebook\n",
        "\n",
        "Este notebook hace RAG sobre `mercadona_data.xlsx`, recupera filas relevantes y llama a OpenAI para responder usando solo ese contexto.\n",
        "\n",
        "## Requisitos\n",
        "- Tener `OPENAI_API_KEY` en variables de entorno.\n",
        "- Tener `openai`, `pandas`, `numpy`, `openpyxl` instalados en `/home/wencm/Alimentación/lib`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ffcf8ec5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Excel: /home/wencm/Alimentación/mercadona_data.xlsx\n",
            "Cache: /home/wencm/Alimentación/rag_cache\n",
            "Python: /home/wencm/WhaRAGBot/.venv/bin/python\n",
            "OPENAI_API_KEY presente: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "LIB_DIR = Path('/home/wencm/Alimentación/lib')\n",
        "if str(LIB_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(LIB_DIR))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "BASE_DIR = Path('/home/wencm/Alimentación')\n",
        "EXCEL_PATH = BASE_DIR / 'mercadona_data.xlsx'\n",
        "CACHE_DIR = BASE_DIR / 'rag_cache'\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "ENV_PATH = BASE_DIR / '.env'\n",
        "\n",
        "CHUNKS_CSV = CACHE_DIR / 'chunks.csv'\n",
        "EMB_NPY = CACHE_DIR / 'embeddings.npy'\n",
        "\n",
        "EMBED_MODEL = 'text-embedding-3-small'\n",
        "CHAT_MODEL = 'gpt-4.1-mini'\n",
        "\n",
        "def load_env_file(path: Path) -> bool:\n",
        "    if not path.exists():\n",
        "        return False\n",
        "\n",
        "    loaded_any = False\n",
        "    for raw_line in path.read_text(encoding='utf-8').splitlines():\n",
        "        line = raw_line.strip()\n",
        "        if not line or line.startswith('#') or '=' not in line:\n",
        "            continue\n",
        "\n",
        "        key, value = line.split('=', 1)\n",
        "        key = key.strip()\n",
        "        value = value.strip()\n",
        "\n",
        "        if (value.startswith('\"') and value.endswith('\"')) or (value.startswith(\"'\") and value.endswith(\"'\")):\n",
        "            value = value[1:-1]\n",
        "\n",
        "        if key and key not in os.environ:\n",
        "            os.environ[key] = value\n",
        "            loaded_any = True\n",
        "\n",
        "    return loaded_any\n",
        "\n",
        "if not os.getenv('OPENAI_API_KEY'):\n",
        "    loaded = load_env_file(ENV_PATH)\n",
        "    if loaded:\n",
        "        print(f'Variables cargadas desde: {ENV_PATH}')\n",
        "\n",
        "print(f'Excel: {EXCEL_PATH}')\n",
        "print(f'Cache: {CACHE_DIR}')\n",
        "print(f'Python: {sys.executable}')\n",
        "print('OPENAI_API_KEY presente:', bool(os.getenv('OPENAI_API_KEY')))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c49c89ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 4553\n",
            "Chunks guardados en: /home/wencm/Alimentación/rag_cache/chunks.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_idx</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>subsubcategory</th>\n",
              "      <th>packaging</th>\n",
              "      <th>unit_size</th>\n",
              "      <th>size_format</th>\n",
              "      <th>price_unit</th>\n",
              "      <th>price_bulk</th>\n",
              "      <th>ingredientes</th>\n",
              "      <th>alergenos</th>\n",
              "      <th>nutrition_ocr_text</th>\n",
              "      <th>text</th>\n",
              "      <th>lexical_text</th>\n",
              "      <th>ingredient_search_text</th>\n",
              "      <th>ingredient_desc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4241.0</td>\n",
              "      <td>Aceite de oliva 0,4º Hacendado</td>\n",
              "      <td>Aceite, especias y salsas</td>\n",
              "      <td>Aceite, vinagre y sal</td>\n",
              "      <td>Aceite de oliva</td>\n",
              "      <td>Garrafa</td>\n",
              "      <td>5.0</td>\n",
              "      <td>l</td>\n",
              "      <td>19.75</td>\n",
              "      <td>3.95</td>\n",
              "      <td>Ingredientes: Aceite de oliva refinado y Aceit...</td>\n",
              "      <td>x99.</td>\n",
              "      <td>Aceitede Oliva | Que contiene exclusivamente |...</td>\n",
              "      <td>Producto: Aceite de oliva 0,4º Hacendado\\nID p...</td>\n",
              "      <td>Aceite de oliva 0,4º Hacendado Aceite, especia...</td>\n",
              "      <td>Aceite de oliva 0,4º Hacendado Aceite, especia...</td>\n",
              "      <td>Ingredientes: Aceite de oliva refinado y Aceit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4240.0</td>\n",
              "      <td>Aceite de oliva 0,4º Hacendado</td>\n",
              "      <td>Aceite, especias y salsas</td>\n",
              "      <td>Aceite, vinagre y sal</td>\n",
              "      <td>Aceite de oliva</td>\n",
              "      <td>Botella</td>\n",
              "      <td>1.0</td>\n",
              "      <td>l</td>\n",
              "      <td>4.10</td>\n",
              "      <td>4.10</td>\n",
              "      <td>Ingredientes: Aceite de oliva refinado y Aceit...</td>\n",
              "      <td>x99.</td>\n",
              "      <td>INGREDIENTES | CONSERVACION | Aceite de oliva ...</td>\n",
              "      <td>Producto: Aceite de oliva 0,4º Hacendado\\nID p...</td>\n",
              "      <td>Aceite de oliva 0,4º Hacendado Aceite, especia...</td>\n",
              "      <td>Aceite de oliva 0,4º Hacendado Aceite, especia...</td>\n",
              "      <td>Ingredientes: Aceite de oliva refinado y Aceit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_idx  product_id                    product_name  \\\n",
              "0        0      4241.0  Aceite de oliva 0,4º Hacendado   \n",
              "1        1      4240.0  Aceite de oliva 0,4º Hacendado   \n",
              "\n",
              "                    category            subcategory   subsubcategory  \\\n",
              "0  Aceite, especias y salsas  Aceite, vinagre y sal  Aceite de oliva   \n",
              "1  Aceite, especias y salsas  Aceite, vinagre y sal  Aceite de oliva   \n",
              "\n",
              "  packaging  unit_size size_format  price_unit  price_bulk  \\\n",
              "0   Garrafa        5.0           l       19.75        3.95   \n",
              "1   Botella        1.0           l        4.10        4.10   \n",
              "\n",
              "                                        ingredientes alergenos  \\\n",
              "0  Ingredientes: Aceite de oliva refinado y Aceit...      x99.   \n",
              "1  Ingredientes: Aceite de oliva refinado y Aceit...      x99.   \n",
              "\n",
              "                                  nutrition_ocr_text  \\\n",
              "0  Aceitede Oliva | Que contiene exclusivamente |...   \n",
              "1  INGREDIENTES | CONSERVACION | Aceite de oliva ...   \n",
              "\n",
              "                                                text  \\\n",
              "0  Producto: Aceite de oliva 0,4º Hacendado\\nID p...   \n",
              "1  Producto: Aceite de oliva 0,4º Hacendado\\nID p...   \n",
              "\n",
              "                                        lexical_text  \\\n",
              "0  Aceite de oliva 0,4º Hacendado Aceite, especia...   \n",
              "1  Aceite de oliva 0,4º Hacendado Aceite, especia...   \n",
              "\n",
              "                              ingredient_search_text  \\\n",
              "0  Aceite de oliva 0,4º Hacendado Aceite, especia...   \n",
              "1  Aceite de oliva 0,4º Hacendado Aceite, especia...   \n",
              "\n",
              "                                ingredient_desc_text  \n",
              "0  Ingredientes: Aceite de oliva refinado y Aceit...  \n",
              "1  Ingredientes: Aceite de oliva refinado y Aceit...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _clean(v):\n",
        "    if pd.isna(v):\n",
        "        return ''\n",
        "    s = str(v).strip()\n",
        "    return '' if s.lower() == 'nan' else s\n",
        "\n",
        "def _numeric(v):\n",
        "    if pd.isna(v):\n",
        "        return ''\n",
        "    try:\n",
        "        f = float(v)\n",
        "    except Exception:\n",
        "        return _clean(v)\n",
        "    return f'{f:g}'\n",
        "\n",
        "def build_row_text(row):\n",
        "    parts = []\n",
        "    parts.append(f\"Producto: {_clean(row.get('product_name'))}\")\n",
        "    parts.append(f\"ID producto: {_numeric(row.get('product_id'))}\")\n",
        "    parts.append(f\"Categoria: {_clean(row.get('category'))} > {_clean(row.get('subcategory'))} > {_clean(row.get('subsubcategory'))}\")\n",
        "    parts.append(f\"Formato: {_clean(row.get('packaging'))}, {_numeric(row.get('unit_size'))} {_clean(row.get('size_format'))}\")\n",
        "    parts.append(f\"Precio unidad: {_numeric(row.get('price_unit'))} EUR\")\n",
        "    parts.append(f\"Precio por volumen/peso: {_numeric(row.get('price_bulk'))} EUR\")\n",
        "    parts.append(f\"Ingredientes: {_clean(row.get('Ingredientes'))}\")\n",
        "    parts.append(f\"Alergenos: {_clean(row.get('Alérgenos'))}\")\n",
        "    parts.append(\n",
        "        'Nutricion por 100g/ml: '\n",
        "        f\"kJ={_numeric(row.get('nutrition_kj_100'))}; \"\n",
        "        f\"kcal={_numeric(row.get('nutrition_kcal_100'))}; \"\n",
        "        f\"grasas={_numeric(row.get('nutrition_fat_g_100'))} g; \"\n",
        "        f\"saturadas={_numeric(row.get('nutrition_saturates_g_100'))} g; \"\n",
        "        f\"hidratos={_numeric(row.get('nutrition_carbs_g_100'))} g; \"\n",
        "        f\"azucares={_numeric(row.get('nutrition_sugars_g_100'))} g; \"\n",
        "        f\"proteinas={_numeric(row.get('nutrition_protein_g_100'))} g; \"\n",
        "        f\"sal={_numeric(row.get('nutrition_salt_g_100'))} g\"\n",
        "    )\n",
        "    parts.append(f\"Imagen principal: {_clean(row.get('thumbnail_url'))}\")\n",
        "    parts.append(f\"Imagenes: {_clean(row.get('photo_urls'))}\")\n",
        "    return '\\n'.join(parts)\n",
        "\n",
        "df = pd.read_excel(EXCEL_PATH)\n",
        "print('Filas:', len(df))\n",
        "\n",
        "chunks = pd.DataFrame({\n",
        "    'row_idx': np.arange(len(df), dtype=int),\n",
        "    'product_id': df.get('product_id'),\n",
        "    'product_name': df.get('product_name'),\n",
        "    'category': df.get('category'),\n",
        "    'subcategory': df.get('subcategory'),\n",
        "    'subsubcategory': df.get('subsubcategory'),\n",
        "    'packaging': df.get('packaging'),\n",
        "    'unit_size': df.get('unit_size'),\n",
        "    'size_format': df.get('size_format'),\n",
        "    'price_unit': df.get('price_unit'),\n",
        "    'price_bulk': df.get('price_bulk'),\n",
        "    'ingredientes': df.get('Ingredientes'),\n",
        "    'alergenos': df.get('Alérgenos'),\n",
        "    'nutrition_ocr_text': df.get('nutrition_ocr_text'),\n",
        "    'text': [build_row_text(r) for _, r in df.iterrows()],\n",
        "})\n",
        "\n",
        "chunks['lexical_text'] = (\n",
        "    chunks['product_name'].fillna('').astype(str) + ' ' +\n",
        "    chunks['category'].fillna('').astype(str) + ' ' +\n",
        "    chunks['subcategory'].fillna('').astype(str) + ' ' +\n",
        "    chunks['subsubcategory'].fillna('').astype(str) + ' ' +\n",
        "    chunks['ingredientes'].fillna('').astype(str)\n",
        ")\n",
        "\n",
        "# Ingredient-focused name/index fields (high precision)\n",
        "chunks['ingredient_search_text'] = (\n",
        "    chunks['product_name'].fillna('').astype(str) + ' ' +\n",
        "    chunks['category'].fillna('').astype(str) + ' ' +\n",
        "    chunks['subcategory'].fillna('').astype(str) + ' ' +\n",
        "    chunks['subsubcategory'].fillna('').astype(str)\n",
        ")\n",
        "\n",
        "# Ingredient-focused description fields (high recall)\n",
        "chunks['ingredient_desc_text'] = (\n",
        "    chunks['ingredientes'].fillna('').astype(str) + ' ' +\n",
        "    chunks['alergenos'].fillna('').astype(str) + ' ' +\n",
        "    chunks['nutrition_ocr_text'].fillna('').astype(str).str.slice(0, 2500)\n",
        ")\n",
        "\n",
        "chunks.to_csv(CHUNKS_CSV, index=False)\n",
        "print('Chunks guardados en:', CHUNKS_CSV)\n",
        "chunks.head(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "119990a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.getenv('OPENAI_API_KEY'):\n",
        "    raise RuntimeError(\n",
        "        'Falta OPENAI_API_KEY. Define la variable en tu entorno o crea '\n",
        "        f\"{ENV_PATH}\"\n",
        "        ' con una linea: OPENAI_API_KEY=tu_clave'\n",
        "    )\n",
        "\n",
        "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
        "\n",
        "def _l2_normalize(arr):\n",
        "    norms = np.linalg.norm(arr, axis=1, keepdims=True) + 1e-12\n",
        "    return arr / norms\n",
        "\n",
        "def embed_texts(texts, model=EMBED_MODEL, batch_size=64):\n",
        "    vectors = []\n",
        "    for start in range(0, len(texts), batch_size):\n",
        "        batch = texts[start:start + batch_size]\n",
        "        resp = client.embeddings.create(model=model, input=batch)\n",
        "        batch_vecs = [d.embedding for d in resp.data]\n",
        "        vectors.extend(batch_vecs)\n",
        "        print(f'Embeddings: {min(start + batch_size, len(texts))}/{len(texts)}')\n",
        "    arr = np.array(vectors, dtype=np.float32)\n",
        "    return _l2_normalize(arr)\n",
        "\n",
        "def ensure_embeddings(chunks_df, force_rebuild=False):\n",
        "    if EMB_NPY.exists() and not force_rebuild:\n",
        "        emb = np.load(EMB_NPY)\n",
        "        if emb.shape[0] == len(chunks_df):\n",
        "            print('Embeddings cargados desde cache:', EMB_NPY)\n",
        "            return emb\n",
        "        print('Cache invalida por numero de filas. Se regenera.')\n",
        "\n",
        "    emb = embed_texts(chunks_df['text'].tolist())\n",
        "    np.save(EMB_NPY, emb)\n",
        "    print('Embeddings guardados en:', EMB_NPY)\n",
        "    return emb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "307d99da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings cargados desde cache: /home/wencm/Alimentación/rag_cache/embeddings.npy\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(4553, 1536)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings = ensure_embeddings(chunks)\n",
        "embeddings.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7c03af00",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    'Eres un asistente experto en el catalogo de Mercadona. '\n",
        "    'Responde SOLO con la informacion del contexto recuperado. '\n",
        "    'Si no hay evidencia suficiente, di claramente que no aparece en el dataset. '\n",
        "    'Si la pregunta es una receta, construye una lista de compra realista para el numero de personas '\n",
        "    'usando productos presentes en el contexto, y separa siempre: '\n",
        "    '1) coste de compra real (envases completos), '\n",
        "    '2) escandallo real del plato (coste consumido). '\n",
        "    'Si falta precio de algun ingrediente, indicalo explicitamente.'\n",
        ")\n",
        "\n",
        "RECIPE_TRIGGERS = (\n",
        "    'receta', 'rehogado', 'rehogar', 'guiso', 'cocinar', 'ingredientes',\n",
        "    'personas', 'menu', 'plato', 'preparar'\n",
        ")\n",
        "\n",
        "STOPWORDS = {\n",
        "    'de', 'la', 'el', 'los', 'las', 'un', 'una', 'unos', 'unas', 'para', 'por', 'con', 'sin',\n",
        "    'que', 'del', 'al', 'en', 'y', 'o', 'a', 'se', 'su', 'sus', 'como', 'dime', 'quiero',\n",
        "    'hacer', 'preparar', 'receta', 'personas', 'plato', 'menu'\n",
        "}\n",
        "\n",
        "# Cantidades base estimadas para 4 personas (unidad compatible con dataset: kg/l/ud)\n",
        "RECIPE_REQUIREMENTS_BASE_4P = {\n",
        "    'lentejas': (0.40, 'kg'),\n",
        "    'arroz': (0.32, 'kg'),\n",
        "    'marisco': (0.45, 'kg'),\n",
        "    'caldo de marisco': (1.00, 'l'),\n",
        "    'caldo': (1.00, 'l'),\n",
        "    'tomate': (0.20, 'kg'),\n",
        "    'cebolla': (0.15, 'kg'),\n",
        "    'ajo': (0.02, 'kg'),\n",
        "    'pimiento': (0.15, 'kg'),\n",
        "    'zanahoria': (0.15, 'kg'),\n",
        "    'aceite de oliva': (0.06, 'l'),\n",
        "    'sal': (0.01, 'kg'),\n",
        "    'pimenton': (0.005, 'kg'),\n",
        "    'laurel': (0.002, 'kg'),\n",
        "}\n",
        "\n",
        "def normalize_text(text):\n",
        "    if text is None:\n",
        "        return ''\n",
        "    text = str(text).lower()\n",
        "    text = unicodedata.normalize('NFD', text)\n",
        "    return ''.join(ch for ch in text if unicodedata.category(ch) != 'Mn')\n",
        "\n",
        "def _token_variants(token):\n",
        "    variants = {token}\n",
        "    if len(token) > 4 and token.endswith('es'):\n",
        "        variants.add(token[:-2])\n",
        "    if len(token) > 3 and token.endswith('s'):\n",
        "        variants.add(token[:-1])\n",
        "    return variants\n",
        "\n",
        "def tokenize(text):\n",
        "    raw = re.findall(r'[a-z0-9]+', normalize_text(text))\n",
        "    out = []\n",
        "    for tok in raw:\n",
        "        out.extend(_token_variants(tok))\n",
        "    return out\n",
        "\n",
        "def _safe_float(v):\n",
        "    try:\n",
        "        if v is None:\n",
        "            return None\n",
        "        if isinstance(v, str) and not v.strip():\n",
        "            return None\n",
        "        return float(v)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _fmt_money(v):\n",
        "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
        "        return '-'\n",
        "    return f'{v:.2f}'\n",
        "\n",
        "def _fmt_num(v, digits=3):\n",
        "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
        "        return '-'\n",
        "    return f'{v:.{digits}f}'\n",
        "\n",
        "def _to_dim_base(value, unit):\n",
        "    value = _safe_float(value)\n",
        "    unit_n = normalize_text(unit)\n",
        "    if value is None:\n",
        "        return None, None\n",
        "\n",
        "    if unit_n == 'kg':\n",
        "        return 'mass_kg', value\n",
        "    if unit_n == 'g':\n",
        "        return 'mass_kg', value / 1000.0\n",
        "    if unit_n == 'l':\n",
        "        return 'vol_l', value\n",
        "    if unit_n == 'ml':\n",
        "        return 'vol_l', value / 1000.0\n",
        "    if unit_n in ('ud', 'u', 'unidad', 'unidades'):\n",
        "        return 'unit_ud', value\n",
        "    return None, None\n",
        "\n",
        "def parse_servings(query, default=4):\n",
        "    qn = normalize_text(query)\n",
        "    m = re.search(r'(\\d+)\\s*personas?', qn)\n",
        "    if m:\n",
        "        try:\n",
        "            n = int(m.group(1))\n",
        "            if n > 0:\n",
        "                return n\n",
        "        except Exception:\n",
        "            pass\n",
        "    return default\n",
        "\n",
        "def is_recipe_query(query):\n",
        "    qn = normalize_text(query)\n",
        "    return any(trigger in qn for trigger in RECIPE_TRIGGERS)\n",
        "\n",
        "def _remove_redundant_ingredients(items):\n",
        "    normalized = [(item, normalize_text(item)) for item in items]\n",
        "    keep = []\n",
        "\n",
        "    for i, (item, norm_item) in enumerate(normalized):\n",
        "        redundant = False\n",
        "        for j, (_, norm_other) in enumerate(normalized):\n",
        "            if i == j:\n",
        "                continue\n",
        "            if norm_item in norm_other and len(norm_item.split()) < len(norm_other.split()):\n",
        "                redundant = True\n",
        "                break\n",
        "        if not redundant:\n",
        "            keep.append(item)\n",
        "\n",
        "    return keep\n",
        "\n",
        "def _extract_json_list(text):\n",
        "    text = text.strip()\n",
        "    if not text:\n",
        "        return []\n",
        "\n",
        "    # 1) Try raw JSON first\n",
        "    try:\n",
        "        obj = json.loads(text)\n",
        "        if isinstance(obj, list):\n",
        "            return obj\n",
        "        if isinstance(obj, dict) and isinstance(obj.get('ingredients'), list):\n",
        "            return obj['ingredients']\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) Try to capture first JSON list in markdown or prose\n",
        "    m = re.search(r'\\[[\\s\\S]*\\]', text)\n",
        "    if m:\n",
        "        try:\n",
        "            obj = json.loads(m.group(0))\n",
        "            if isinstance(obj, list):\n",
        "                return obj\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return []\n",
        "\n",
        "def _clean_ingredient_name(item):\n",
        "    s = normalize_text(item)\n",
        "    s = re.sub(r'\\([^)]*\\)', ' ', s)\n",
        "    s = re.sub(r'\\baprox(?:imadamente)?\\b', ' ', s)\n",
        "\n",
        "    # Remove leading quantity/unit chunks: \"400 g de\", \"2 dientes de\", etc.\n",
        "    s = re.sub(\n",
        "        r'^\\s*\\d+(?:[\\.,]\\d+)?\\s*(kg|g|gr|gramos?|ml|l|litros?|unidad(?:es)?|ud|dientes?|cucharad(?:a|as)|taza(?:s)?)?\\s*(de\\s+)?',\n",
        "        '',\n",
        "        s,\n",
        "    )\n",
        "    s = re.sub(r'^\\s*(unos?|unas?|un|una)\\s+', '', s)\n",
        "\n",
        "    # Remove residual quantities/units inside phrase.\n",
        "    s = re.sub(r'\\b\\d+(?:[\\.,]\\d+)?\\b', ' ', s)\n",
        "    s = re.sub(r'\\b(kg|g|gr|gramos?|ml|l|litros?|unidad(?:es)?|ud|dientes?|cucharad(?:a|as)|taza(?:s)?)\\b', ' ', s)\n",
        "\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    if s.startswith('de '):\n",
        "        s = s[3:].strip()\n",
        "\n",
        "    return s\n",
        "\n",
        "def infer_recipe_ingredients_llm(query, max_items=12):\n",
        "    prompt = (\n",
        "        'Extrae ingredientes para la receta solicitada. '\n",
        "        'Devuelve SOLO un JSON array de strings, sin texto adicional. '\n",
        "        'No incluyas cantidades ni unidades. '\n",
        "        'Incluye ingredientes base y condimentos habituales. '\n",
        "        'No incluyas bebidas, refrescos ni acompanamientos opcionales. '\n",
        "        f'Consulta: {query}'\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        resp = client.responses.create(\n",
        "            model=CHAT_MODEL,\n",
        "            input=prompt,\n",
        "        )\n",
        "        raw = (resp.output_text or '').strip()\n",
        "        arr = _extract_json_list(raw)\n",
        "\n",
        "        out = []\n",
        "        seen = set()\n",
        "        for x in arr:\n",
        "            if not isinstance(x, str):\n",
        "                continue\n",
        "            item = _clean_ingredient_name(x)\n",
        "            if len(item) < 2:\n",
        "                continue\n",
        "            key = normalize_text(item)\n",
        "            if not key or key in seen:\n",
        "                continue\n",
        "            seen.add(key)\n",
        "            out.append(item)\n",
        "            if len(out) >= max_items:\n",
        "                break\n",
        "\n",
        "        return out\n",
        "    except Exception as exc:\n",
        "        print(f'WARN infer_recipe_ingredients_llm fallo: {exc}')\n",
        "        return []\n",
        "\n",
        "def infer_recipe_ingredients(query):\n",
        "    if not is_recipe_query(query):\n",
        "        return []\n",
        "\n",
        "    inferred = infer_recipe_ingredients_llm(query)\n",
        "    if inferred:\n",
        "        return _remove_redundant_ingredients(inferred)\n",
        "\n",
        "    # Fallback sin reglas de plato concreto\n",
        "    tokens = [\n",
        "        t for t in tokenize(query)\n",
        "        if len(t) > 2 and t not in STOPWORDS and not t.isdigit()\n",
        "    ]\n",
        "    return _remove_redundant_ingredients(tokens[:8])\n",
        "\n",
        "def _ingredient_requirement_key(ingredient):\n",
        "    ing_n = normalize_text(ingredient)\n",
        "    keys = sorted(RECIPE_REQUIREMENTS_BASE_4P.keys(), key=len, reverse=True)\n",
        "    for key in keys:\n",
        "        if key in ing_n:\n",
        "            return key\n",
        "    return None\n",
        "\n",
        "def estimate_required_quantity(ingredient, servings=4):\n",
        "    key = _ingredient_requirement_key(ingredient)\n",
        "    if key is None:\n",
        "        return 1.0 * (servings / 4.0), 'ud', 'fallback'\n",
        "\n",
        "    base_qty, base_unit = RECIPE_REQUIREMENTS_BASE_4P[key]\n",
        "    factor = servings / 4.0\n",
        "    return base_qty * factor, base_unit, key\n",
        "\n",
        "def expand_subqueries(query, recipe_mode='auto'):\n",
        "    subqueries = [query]\n",
        "    inferred_ingredients = []\n",
        "\n",
        "    use_recipe = (recipe_mode is True) or (recipe_mode == 'auto' and is_recipe_query(query))\n",
        "    if use_recipe:\n",
        "        inferred_ingredients = infer_recipe_ingredients(query)\n",
        "        for ingredient in inferred_ingredients:\n",
        "            subqueries.append(f'{ingredient} mercadona precio')\n",
        "\n",
        "    return subqueries, inferred_ingredients\n",
        "\n",
        "# General index (RAG context)\n",
        "DOC_TOKENS = [tokenize(text) for text in chunks['lexical_text'].fillna('')]\n",
        "POSTINGS = defaultdict(list)\n",
        "DOC_FREQ = defaultdict(int)\n",
        "N_DOCS = len(DOC_TOKENS)\n",
        "\n",
        "for doc_idx, toks in enumerate(DOC_TOKENS):\n",
        "    counts = Counter(toks)\n",
        "    for tok, tf in counts.items():\n",
        "        POSTINGS[tok].append((doc_idx, tf))\n",
        "        DOC_FREQ[tok] += 1\n",
        "\n",
        "# Ingredient-focused indexes\n",
        "# 1) Name/category index (precision)\n",
        "ING_NAME_DOC_TOKENS = [tokenize(text) for text in chunks['ingredient_search_text'].fillna('')]\n",
        "ING_NAME_TOKEN_SETS = [set(toks) for toks in ING_NAME_DOC_TOKENS]\n",
        "ING_NAME_POSTINGS = defaultdict(list)\n",
        "ING_NAME_DOC_FREQ = defaultdict(int)\n",
        "\n",
        "for doc_idx, toks in enumerate(ING_NAME_DOC_TOKENS):\n",
        "    counts = Counter(toks)\n",
        "    for tok, tf in counts.items():\n",
        "        ING_NAME_POSTINGS[tok].append((doc_idx, tf))\n",
        "        ING_NAME_DOC_FREQ[tok] += 1\n",
        "\n",
        "# 2) Description/ingredients index (recall)\n",
        "ING_DESC_DOC_TOKENS = [tokenize(text) for text in chunks['ingredient_desc_text'].fillna('')]\n",
        "ING_DESC_TOKEN_SETS = [set(toks) for toks in ING_DESC_DOC_TOKENS]\n",
        "ING_DESC_POSTINGS = defaultdict(list)\n",
        "ING_DESC_DOC_FREQ = defaultdict(int)\n",
        "\n",
        "for doc_idx, toks in enumerate(ING_DESC_DOC_TOKENS):\n",
        "    counts = Counter(toks)\n",
        "    for tok, tf in counts.items():\n",
        "        ING_DESC_POSTINGS[tok].append((doc_idx, tf))\n",
        "        ING_DESC_DOC_FREQ[tok] += 1\n",
        "\n",
        "def _tfidf_scores_index(q_tokens, postings, doc_freq):\n",
        "    if not q_tokens:\n",
        "        return np.zeros(N_DOCS, dtype=np.float32)\n",
        "\n",
        "    q_counts = Counter(q_tokens)\n",
        "    scores = np.zeros(N_DOCS, dtype=np.float32)\n",
        "\n",
        "    for tok, qtf in q_counts.items():\n",
        "        rows = postings.get(tok)\n",
        "        if not rows:\n",
        "            continue\n",
        "\n",
        "        idf = math.log((N_DOCS + 1) / (doc_freq[tok] + 1)) + 1.0\n",
        "        q_weight = 1.0 + math.log(qtf)\n",
        "        for doc_i, tf in rows:\n",
        "            scores[doc_i] += q_weight * (1.0 + math.log(tf)) * idf\n",
        "\n",
        "    max_score = float(scores.max())\n",
        "    if max_score > 0:\n",
        "        scores /= max_score\n",
        "    return scores\n",
        "\n",
        "def lexical_scores(query):\n",
        "    q_tokens = [t for t in tokenize(query) if len(t) > 2 and t not in STOPWORDS]\n",
        "    return _tfidf_scores_index(q_tokens, POSTINGS, DOC_FREQ)\n",
        "\n",
        "def lexical_scores_ingredient(query):\n",
        "    q_tokens = [t for t in tokenize(query) if len(t) > 2 and t not in STOPWORDS]\n",
        "    name_scores = _tfidf_scores_index(q_tokens, ING_NAME_POSTINGS, ING_NAME_DOC_FREQ)\n",
        "    desc_scores = _tfidf_scores_index(q_tokens, ING_DESC_POSTINGS, ING_DESC_DOC_FREQ)\n",
        "\n",
        "    # Name/category drives precision; ingredients/description improves recall for indirect product names.\n",
        "    return 0.80 * name_scores + 0.20 * desc_scores\n",
        "\n",
        "def semantic_scores_batch(queries):\n",
        "    resp = client.embeddings.create(model=EMBED_MODEL, input=queries)\n",
        "    all_scores = []\n",
        "    for item in resp.data:\n",
        "        q_vec = np.array(item.embedding, dtype=np.float32)\n",
        "        q_vec = q_vec / (np.linalg.norm(q_vec) + 1e-12)\n",
        "        sem = embeddings @ q_vec\n",
        "        all_scores.append((sem + 1.0) / 2.0)\n",
        "    return all_scores\n",
        "\n",
        "def _ingredient_token_masks(ingredient):\n",
        "    tokens = [t for t in tokenize(ingredient) if t not in STOPWORDS and len(t) > 2]\n",
        "    if not tokens:\n",
        "        zeros = np.zeros(N_DOCS, dtype=bool)\n",
        "        return zeros, zeros\n",
        "\n",
        "    any_mask = np.zeros(N_DOCS, dtype=bool)\n",
        "    all_mask = np.zeros(N_DOCS, dtype=bool)\n",
        "\n",
        "    for doc_i, tokset in enumerate(ING_NAME_TOKEN_SETS):\n",
        "        present = [tok in tokset for tok in tokens]\n",
        "        if any(present):\n",
        "            any_mask[doc_i] = True\n",
        "        if all(present):\n",
        "            all_mask[doc_i] = True\n",
        "\n",
        "    return any_mask, all_mask\n",
        "\n",
        "def retrieve_hybrid(query, top_k=20, alpha=0.65, recipe_mode='auto'):\n",
        "    subqueries, inferred_ingredients = expand_subqueries(query, recipe_mode=recipe_mode)\n",
        "    sem_scores_list = semantic_scores_batch(subqueries)\n",
        "\n",
        "    hybrid_best = np.zeros(N_DOCS, dtype=np.float32)\n",
        "    semantic_best = np.zeros(N_DOCS, dtype=np.float32)\n",
        "    lexical_best = np.zeros(N_DOCS, dtype=np.float32)\n",
        "\n",
        "    for subquery, sem_scores in zip(subqueries, sem_scores_list):\n",
        "        lex_scores = lexical_scores(subquery)\n",
        "        hybrid_scores = alpha * sem_scores + (1.0 - alpha) * lex_scores\n",
        "\n",
        "        hybrid_best = np.maximum(hybrid_best, hybrid_scores)\n",
        "        semantic_best = np.maximum(semantic_best, sem_scores)\n",
        "        lexical_best = np.maximum(lexical_best, lex_scores)\n",
        "\n",
        "    top_idx = np.argsort(-hybrid_best)[:top_k]\n",
        "\n",
        "    hits = chunks.iloc[top_idx].copy()\n",
        "    hits['score'] = hybrid_best[top_idx]\n",
        "    hits['score_semantic'] = semantic_best[top_idx]\n",
        "    hits['score_lexical'] = lexical_best[top_idx]\n",
        "\n",
        "    return hits.sort_values('score', ascending=False).reset_index(drop=True), subqueries, inferred_ingredients\n",
        "\n",
        "def retrieve(query, top_k=8, mode='hybrid', alpha=0.65, recipe_mode='auto'):\n",
        "    mode = mode.lower()\n",
        "\n",
        "    if mode == 'semantic':\n",
        "        sem_scores = semantic_scores_batch([query])[0]\n",
        "        top_idx = np.argsort(-sem_scores)[:top_k]\n",
        "        hits = chunks.iloc[top_idx].copy()\n",
        "        hits['score'] = sem_scores[top_idx]\n",
        "        return hits.sort_values('score', ascending=False).reset_index(drop=True), [query], []\n",
        "\n",
        "    if mode == 'hybrid':\n",
        "        return retrieve_hybrid(query, top_k=top_k, alpha=alpha, recipe_mode=recipe_mode)\n",
        "\n",
        "    raise ValueError(\"mode debe ser 'semantic' o 'hybrid'\")\n",
        "\n",
        "def retrieve_products_for_ingredient(ingredient, top_n=10, alpha=0.35, recipe_query=None):\n",
        "    context_query = normalize_text(recipe_query) if recipe_query else ''\n",
        "    search_query = f'{ingredient} {context_query} mercadona producto precio'.strip()\n",
        "    sem_scores = semantic_scores_batch([search_query])[0]\n",
        "    lex_scores = lexical_scores_ingredient(search_query)\n",
        "\n",
        "    cols = [\n",
        "        'row_idx', 'product_id', 'product_name', 'category', 'subcategory',\n",
        "        'packaging', 'unit_size', 'size_format', 'price_unit', 'price_bulk'\n",
        "    ]\n",
        "\n",
        "    # Safety: if there is no lexical evidence at all, return empty instead of noisy semantic matches.\n",
        "    if float(lex_scores.max()) <= 0.0:\n",
        "        empty = pd.DataFrame(columns=cols)\n",
        "        empty['ingredient'] = []\n",
        "        empty['score_ingredient'] = []\n",
        "        return empty\n",
        "\n",
        "    # Ingredient ranking prioritizes lexical precision over semantic recall.\n",
        "    hybrid_scores = alpha * sem_scores + (1.0 - alpha) * lex_scores\n",
        "\n",
        "    any_mask, all_mask = _ingredient_token_masks(ingredient)\n",
        "    if any_mask.any():\n",
        "        hybrid_scores = np.where(any_mask, hybrid_scores + 0.25, hybrid_scores * 0.10)\n",
        "    if all_mask.any():\n",
        "        hybrid_scores = np.where(all_mask, hybrid_scores + 0.15, hybrid_scores)\n",
        "\n",
        "    candidate_n = min(N_DOCS, max(top_n * 5, top_n))\n",
        "    top_idx = np.argsort(-hybrid_scores)[:candidate_n]\n",
        "\n",
        "    out = chunks.iloc[top_idx][cols].copy()\n",
        "    out['ingredient'] = ingredient\n",
        "    out['score_ingredient'] = hybrid_scores[top_idx]\n",
        "\n",
        "    # Deduplicate same product across duplicated category branches.\n",
        "    out = out.sort_values('score_ingredient', ascending=False).drop_duplicates(subset=['product_id'], keep='first')\n",
        "    return out.head(top_n).reset_index(drop=True)\n",
        "\n",
        "def tool_get_products_for_ingredients(ingredients, per_ingredient=10, alpha=0.35, recipe_query=None):\n",
        "    \"\"\"\n",
        "    Tool-like helper: for each ingredient, returns a ranked product shortlist.\n",
        "    \"\"\"\n",
        "    catalog = {}\n",
        "    for ingredient in ingredients:\n",
        "        hits = retrieve_products_for_ingredient(ingredient, top_n=per_ingredient, alpha=alpha, recipe_query=recipe_query)\n",
        "        catalog[ingredient] = hits\n",
        "    return catalog\n",
        "\n",
        "def _choose_best_candidate(df_hits, required_unit):\n",
        "    if df_hits is None or df_hits.empty:\n",
        "        return None\n",
        "\n",
        "    req_dim, _ = _to_dim_base(1.0, required_unit)\n",
        "\n",
        "    best_any = None\n",
        "    best_dim_match = None\n",
        "\n",
        "    for _, row in df_hits.iterrows():\n",
        "        price = _safe_float(row.get('price_unit'))\n",
        "        unit_size = _safe_float(row.get('unit_size'))\n",
        "        size_fmt = row.get('size_format')\n",
        "        dim, pack_base = _to_dim_base(unit_size, size_fmt)\n",
        "\n",
        "        if price is None:\n",
        "            continue\n",
        "\n",
        "        if best_any is None:\n",
        "            best_any = row\n",
        "\n",
        "        if req_dim is not None and dim == req_dim and pack_base is not None and pack_base > 0:\n",
        "            best_dim_match = row\n",
        "            break\n",
        "\n",
        "    if best_dim_match is not None:\n",
        "        return best_dim_match\n",
        "    if best_any is not None:\n",
        "        return best_any\n",
        "\n",
        "    return df_hits.iloc[0]\n",
        "\n",
        "def _compute_buy_and_escandallo(chosen_row, required_qty, required_unit):\n",
        "    if chosen_row is None:\n",
        "        return {\n",
        "            'units_to_buy': None,\n",
        "            'purchase_cost_eur': None,\n",
        "            'escandallo_cost_eur': None,\n",
        "            'notes': 'Sin producto candidato',\n",
        "        }\n",
        "\n",
        "    price_unit = _safe_float(chosen_row.get('price_unit'))\n",
        "    unit_size = _safe_float(chosen_row.get('unit_size'))\n",
        "    size_format = chosen_row.get('size_format')\n",
        "\n",
        "    req_dim, req_base = _to_dim_base(required_qty, required_unit)\n",
        "    pack_dim, pack_base = _to_dim_base(unit_size, size_format)\n",
        "\n",
        "    if price_unit is None:\n",
        "        return {\n",
        "            'units_to_buy': None,\n",
        "            'purchase_cost_eur': None,\n",
        "            'escandallo_cost_eur': None,\n",
        "            'notes': 'Producto sin price_unit',\n",
        "        }\n",
        "\n",
        "    # Regla clave: compra siempre envase completo (redondeo al alza)\n",
        "    if req_dim is not None and pack_dim == req_dim and pack_base is not None and pack_base > 0 and req_base is not None:\n",
        "        units_to_buy = max(1, math.ceil(req_base / pack_base))\n",
        "        purchase_cost = units_to_buy * price_unit\n",
        "        escandallo_cost = (req_base / pack_base) * price_unit\n",
        "        return {\n",
        "            'units_to_buy': units_to_buy,\n",
        "            'purchase_cost_eur': purchase_cost,\n",
        "            'escandallo_cost_eur': escandallo_cost,\n",
        "            'notes': 'OK unidades comparables',\n",
        "        }\n",
        "\n",
        "    # Fallback: no se puede convertir unidades -> compra minima 1 unidad.\n",
        "    return {\n",
        "        'units_to_buy': 1,\n",
        "        'purchase_cost_eur': price_unit,\n",
        "        'escandallo_cost_eur': None,\n",
        "        'notes': 'Unidad no comparable, compra minima 1 unidad',\n",
        "    }\n",
        "\n",
        "def build_recipe_cost_plan(ingredient_catalog, ingredients, query):\n",
        "    servings = parse_servings(query, default=4)\n",
        "    rows = []\n",
        "\n",
        "    for ingredient in ingredients:\n",
        "        required_qty, required_unit, req_source = estimate_required_quantity(ingredient, servings=servings)\n",
        "        hits = ingredient_catalog.get(ingredient)\n",
        "        chosen = _choose_best_candidate(hits, required_unit)\n",
        "\n",
        "        if chosen is None:\n",
        "            rows.append({\n",
        "                'ingredient': ingredient,\n",
        "                'required_qty': required_qty,\n",
        "                'required_unit': required_unit,\n",
        "                'requirement_source': req_source,\n",
        "                'product_id': None,\n",
        "                'product_name': None,\n",
        "                'unit_size': None,\n",
        "                'size_format': None,\n",
        "                'price_unit': None,\n",
        "                'units_to_buy': None,\n",
        "                'purchase_cost_eur': None,\n",
        "                'escandallo_cost_eur': None,\n",
        "                'notes': 'Sin candidatos',\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        cost_info = _compute_buy_and_escandallo(chosen, required_qty, required_unit)\n",
        "        rows.append({\n",
        "            'ingredient': ingredient,\n",
        "            'required_qty': required_qty,\n",
        "            'required_unit': required_unit,\n",
        "            'requirement_source': req_source,\n",
        "            'product_id': chosen.get('product_id'),\n",
        "            'product_name': chosen.get('product_name'),\n",
        "            'unit_size': _safe_float(chosen.get('unit_size')),\n",
        "            'size_format': chosen.get('size_format'),\n",
        "            'price_unit': _safe_float(chosen.get('price_unit')),\n",
        "            'units_to_buy': cost_info['units_to_buy'],\n",
        "            'purchase_cost_eur': cost_info['purchase_cost_eur'],\n",
        "            'escandallo_cost_eur': cost_info['escandallo_cost_eur'],\n",
        "            'notes': cost_info['notes'],\n",
        "        })\n",
        "\n",
        "    plan_df = pd.DataFrame(rows)\n",
        "\n",
        "    total_purchase = _safe_float(plan_df['purchase_cost_eur'].dropna().sum()) if not plan_df.empty else 0.0\n",
        "    total_escandallo = _safe_float(plan_df['escandallo_cost_eur'].dropna().sum()) if not plan_df.empty else 0.0\n",
        "\n",
        "    missing_purchase = plan_df[plan_df['purchase_cost_eur'].isna()]['ingredient'].tolist() if not plan_df.empty else []\n",
        "    missing_esc = plan_df[plan_df['escandallo_cost_eur'].isna()]['ingredient'].tolist() if not plan_df.empty else []\n",
        "\n",
        "    summary = {\n",
        "        'servings': servings,\n",
        "        'total_purchase_eur': total_purchase,\n",
        "        'total_escandallo_eur': total_escandallo,\n",
        "        'missing_purchase_ingredients': missing_purchase,\n",
        "        'missing_escandallo_ingredients': missing_esc,\n",
        "    }\n",
        "\n",
        "    return plan_df, summary\n",
        "\n",
        "def format_ingredient_catalog_text(catalog, max_items=6):\n",
        "    blocks = []\n",
        "    for ingredient, df_hits in catalog.items():\n",
        "        lines = [f'Ingrediente: {ingredient}']\n",
        "        if df_hits.empty:\n",
        "            lines.append('- Sin candidatos en el dataset')\n",
        "        else:\n",
        "            for _, row in df_hits.head(max_items).iterrows():\n",
        "                lines.append(\n",
        "                    '- '\n",
        "                    f\"product_id={row['product_id']}; \"\n",
        "                    f\"nombre={row['product_name']}; \"\n",
        "                    f\"categoria={row['category']}; \"\n",
        "                    f\"precio_unit={row['price_unit']}; \"\n",
        "                    f\"formato={row['unit_size']} {row['size_format']}; \"\n",
        "                    f\"score={row['score_ingredient']:.4f}\"\n",
        "                )\n",
        "        blocks.append('\\n'.join(lines))\n",
        "    return '\\n\\n'.join(blocks)\n",
        "\n",
        "def format_cost_plan_text(plan_df, summary):\n",
        "    if plan_df is None or plan_df.empty:\n",
        "        return 'Sin plan de costes.'\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Personas: {summary['servings']}\")\n",
        "    lines.append(f\"TOTAL_COMPRA_EUR (envase completo): {_fmt_money(summary['total_purchase_eur'])}\")\n",
        "    lines.append(f\"TOTAL_ESCANDALLO_EUR (consumo real): {_fmt_money(summary['total_escandallo_eur'])}\")\n",
        "\n",
        "    if summary['missing_purchase_ingredients']:\n",
        "        lines.append('Faltan precios de compra para: ' + ', '.join(summary['missing_purchase_ingredients']))\n",
        "    if summary['missing_escandallo_ingredients']:\n",
        "        lines.append('No se pudo calcular escandallo para: ' + ', '.join(summary['missing_escandallo_ingredients']))\n",
        "\n",
        "    lines.append('')\n",
        "    lines.append('| ingrediente | product_id | producto | req_qty | pack_size | price_unit | units_to_buy | purchase_cost_eur | escandallo_cost_eur |')\n",
        "    lines.append('|---|---:|---|---:|---|---:|---:|---:|---:|')\n",
        "\n",
        "    for _, r in plan_df.iterrows():\n",
        "        lines.append(\n",
        "            f\"| {r.get('ingredient')} | {r.get('product_id')} | {r.get('product_name')} | \"\n",
        "            f\"{_fmt_num(r.get('required_qty'), 3)} {r.get('required_unit')} | \"\n",
        "            f\"{_fmt_num(r.get('unit_size'), 3)} {r.get('size_format')} | \"\n",
        "            f\"{_fmt_money(r.get('price_unit'))} | {r.get('units_to_buy')} | \"\n",
        "            f\"{_fmt_money(r.get('purchase_cost_eur'))} | {_fmt_money(r.get('escandallo_cost_eur'))} |\"\n",
        "        )\n",
        "\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "\n",
        "def _fmt_money_es(v):\n",
        "    n = _safe_float(v)\n",
        "    if n is None:\n",
        "        return 'N/D'\n",
        "    return f\"{n:,.2f}\".replace(',', 'X').replace('.', ',').replace('X', '.')\n",
        "\n",
        "def _format_qty_for_recipe_line(ingredient, required_qty, required_unit):\n",
        "    qty = _safe_float(required_qty)\n",
        "    unit = normalize_text(required_unit)\n",
        "    ing = normalize_text(ingredient)\n",
        "\n",
        "    if qty is None:\n",
        "        return 'cantidad N/D'\n",
        "\n",
        "    condiments = ('sal', 'pimienta', 'azafran', 'pimenton', 'laurel')\n",
        "\n",
        "    if unit == 'kg':\n",
        "        grams = qty * 1000.0\n",
        "        if any(c in ing for c in condiments):\n",
        "            if grams <= 6:\n",
        "                return '1 cucharadita'\n",
        "            if grams <= 20:\n",
        "                return '1 cucharada'\n",
        "        if grams < 1000:\n",
        "            return f\"{int(round(grams))} g\"\n",
        "        return f\"{_fmt_num(qty, 2)} kg\"\n",
        "\n",
        "    if unit == 'l':\n",
        "        ml = qty * 1000.0\n",
        "        if 'limon' in ing and ml <= 60:\n",
        "            return '1 chorro'\n",
        "        if 'aceite' in ing and ml <= 80:\n",
        "            return '1 chorro'\n",
        "        if ml < 1000:\n",
        "            return f\"{int(round(ml))} ml\"\n",
        "        return f\"{_fmt_num(qty, 2)} l\"\n",
        "\n",
        "    if unit == 'ud':\n",
        "        if 'limon' in ing:\n",
        "            return '1 chorro'\n",
        "        n = max(1, int(round(qty)))\n",
        "        return f\"{n} ud\"\n",
        "\n",
        "    return f\"{_fmt_num(qty, 2)} {required_unit}\"\n",
        "\n",
        "def build_block1_ingredients_mercadona(plan_df):\n",
        "    if plan_df is None or plan_df.empty:\n",
        "        return 'No se encontraron ingredientes/productos en Mercadona para esta receta.'\n",
        "\n",
        "    lines = []\n",
        "    for _, r in plan_df.iterrows():\n",
        "        ingredient = r.get('ingredient')\n",
        "        product_name = r.get('product_name')\n",
        "        req_qty = r.get('required_qty')\n",
        "        req_unit = r.get('required_unit')\n",
        "\n",
        "        if product_name is None or str(product_name) == 'nan':\n",
        "            lines.append(f\"- {ingredient}: sin producto identificado en el dataset\")\n",
        "            continue\n",
        "\n",
        "        qty_text = _format_qty_for_recipe_line(ingredient, req_qty, req_unit)\n",
        "        lines.append(f\"- {qty_text} {product_name}\")\n",
        "\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "def tool_get_total_purchase_price(cost_summary):\n",
        "    total = _safe_float(cost_summary.get('total_purchase_eur')) if isinstance(cost_summary, dict) else None\n",
        "    if total is None:\n",
        "        return 'Precio de los productos a comprar para esta receta: N/D'\n",
        "    return f\"Precio de los productos a comprar para esta receta: {_fmt_money_es(total)}€\"\n",
        "\n",
        "def _build_recipe_prompt_context(plan_df, max_items=14):\n",
        "    if plan_df is None or plan_df.empty:\n",
        "        return 'No hay productos concretos disponibles.'\n",
        "\n",
        "    lines = []\n",
        "    for _, r in plan_df.head(max_items).iterrows():\n",
        "        product_name = r.get('product_name')\n",
        "        ingredient = r.get('ingredient')\n",
        "        req_qty = _fmt_num(r.get('required_qty'), 3)\n",
        "        req_unit = r.get('required_unit')\n",
        "        if product_name is None or str(product_name) == 'nan':\n",
        "            continue\n",
        "        lines.append(f\"- {ingredient}: {product_name} ({req_qty} {req_unit})\")\n",
        "\n",
        "    return '\\n'.join(lines) if lines else 'No hay productos concretos disponibles.'\n",
        "\n",
        "def build_block3_recipe_text(query, plan_df, model=CHAT_MODEL, max_chars=1000):\n",
        "    context_lines = _build_recipe_prompt_context(plan_df)\n",
        "\n",
        "    prompt = (\n",
        "        f\"Escribe una receta breve en español para esta solicitud: {query}.\\n\"\n",
        "        f\"Usa de referencia estos ingredientes/productos:\\n{context_lines}\\n\\n\"\n",
        "        f\"Reglas estrictas:\\n\"\n",
        "        f\"- Máximo {max_chars} caracteres.\\n\"\n",
        "        f\"- Texto corrido con pasos claros (sin tablas).\\n\"\n",
        "        f\"- No inventes precios.\\n\"\n",
        "        f\"- Devuelve solo el texto de la receta.\"\n",
        "    )\n",
        "\n",
        "    raw_resp = None\n",
        "    text = ''\n",
        "    try:\n",
        "        raw_resp = client.responses.create(model=model, input=prompt)\n",
        "        text = (raw_resp.output_text or '').strip()\n",
        "    except Exception as exc:\n",
        "        text = f\"No se pudo generar el texto de receta automáticamente ({exc}).\"\n",
        "\n",
        "    if len(text) > max_chars:\n",
        "        text = text[: max_chars - 1].rstrip() + '…'\n",
        "\n",
        "    return text, raw_resp\n",
        "\n",
        "def compose_structured_answer(block1, block2, block3):\n",
        "    return (\n",
        "        \"Ingredientes de Mercadona:\\n\"\n",
        "        f\"{block1}\\n\\n\"\n",
        "        f\"{block2}\\n\\n\"\n",
        "        \"Receta y pasos:\\n\"\n",
        "        f\"{block3}\"\n",
        "    )\n",
        "\n",
        "def _catalog_preview(catalog, n=3):\n",
        "    preview = {}\n",
        "    for ing, df_hits in catalog.items():\n",
        "        preview[ing] = [\n",
        "            {\n",
        "                'product_id': r['product_id'],\n",
        "                'product_name': r['product_name'],\n",
        "                'price_unit': r['price_unit'],\n",
        "            }\n",
        "            for _, r in df_hits.head(n).iterrows()\n",
        "        ]\n",
        "    return preview\n",
        "\n",
        "def ask_agent(\n",
        "    query,\n",
        "    top_k=20,\n",
        "    model=CHAT_MODEL,\n",
        "    retrieval_mode='hybrid',\n",
        "    alpha=0.65,\n",
        "    recipe_mode='auto',\n",
        "    use_ingredient_tool=True,\n",
        "    candidates_per_ingredient=10,\n",
        "):\n",
        "    hits, subqueries, inferred_ingredients = retrieve(\n",
        "        query,\n",
        "        top_k=top_k,\n",
        "        mode=retrieval_mode,\n",
        "        alpha=alpha,\n",
        "        recipe_mode=recipe_mode,\n",
        "    )\n",
        "\n",
        "    ingredient_catalog = {}\n",
        "    ingredient_catalog_text = ''\n",
        "    cost_plan_df = pd.DataFrame()\n",
        "    cost_summary = {\n",
        "        'servings': parse_servings(query, default=4),\n",
        "        'total_purchase_eur': 0.0,\n",
        "        'total_escandallo_eur': 0.0,\n",
        "        'missing_purchase_ingredients': [],\n",
        "        'missing_escandallo_ingredients': [],\n",
        "    }\n",
        "    cost_plan_text = 'Sin plan de costes.'\n",
        "\n",
        "    if use_ingredient_tool and inferred_ingredients:\n",
        "        ingredient_catalog = tool_get_products_for_ingredients(\n",
        "            inferred_ingredients,\n",
        "            per_ingredient=candidates_per_ingredient,\n",
        "            alpha=0.35,\n",
        "            recipe_query=query,\n",
        "        )\n",
        "        ingredient_catalog_text = format_ingredient_catalog_text(ingredient_catalog, max_items=6)\n",
        "\n",
        "        cost_plan_df, cost_summary = build_recipe_cost_plan(\n",
        "            ingredient_catalog=ingredient_catalog,\n",
        "            ingredients=inferred_ingredients,\n",
        "            query=query,\n",
        "        )\n",
        "        cost_plan_text = format_cost_plan_text(cost_plan_df, cost_summary)\n",
        "\n",
        "    block_1 = build_block1_ingredients_mercadona(cost_plan_df)\n",
        "    block_2 = tool_get_total_purchase_price(cost_summary)\n",
        "    block_3, raw_resp_block3 = build_block3_recipe_text(query, cost_plan_df, model=model, max_chars=1000)\n",
        "    structured_answer = compose_structured_answer(block_1, block_2, block_3)\n",
        "\n",
        "    hit_cols = [\n",
        "        'product_id', 'product_name', 'category', 'price_unit',\n",
        "        'unit_size', 'size_format', 'score'\n",
        "    ]\n",
        "    for extra in ('score_semantic', 'score_lexical'):\n",
        "        if extra in hits.columns:\n",
        "            hit_cols.append(extra)\n",
        "\n",
        "    return {\n",
        "        'answer': structured_answer,\n",
        "        'block_1': block_1,\n",
        "        'block_2': block_2,\n",
        "        'block_3': block_3,\n",
        "        'hits': hits[hit_cols],\n",
        "        'subqueries': subqueries,\n",
        "        'inferred_ingredients': inferred_ingredients,\n",
        "        'ingredient_catalog': ingredient_catalog,\n",
        "        'ingredient_catalog_preview': _catalog_preview(ingredient_catalog, n=3),\n",
        "        'cost_plan': cost_plan_df,\n",
        "        'cost_summary': cost_summary,\n",
        "        'cost_plan_text': cost_plan_text,\n",
        "        'ingredient_catalog_text': ingredient_catalog_text,\n",
        "        'raw_response': raw_resp_block3,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f163e664",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingredientes de Mercadona:\n",
            "- 320 g Arroz marinera Hacendado ultracongelado\n",
            "- 1.00 l Caldo de marisco o fideuá para paella Hacendado con sofrito\n",
            "- 1 ud Salteado de gambas, espárragos verdes, ajos tiernos, champiñón y cebolla Hacendado ultracongelado\n",
            "- 1 ud Mejillones en escabeche Hacendado medianos\n",
            "- 1 ud Calamar troceado limpio Hacendado congelado\n",
            "- 1 ud Concha fina al natural Hacendado\n",
            "- 200 g Tomate doble concentrado Hacendado extra\n",
            "- 150 g Pimiento rojo\n",
            "- 150 g Cebollas\n",
            "- 20 g Picada de ajo y perejil\n",
            "- 1 chorro Aceite de oliva 1º Hacendado\n",
            "- 1 ud Sazonador para paella con azafrán Hacendado\n",
            "\n",
            "Precio de los productos a comprar para esta receta: 48,48€\n",
            "\n",
            "Receta y pasos:\n",
            "Calienta el aceite de oliva en una paellera y sofríe la cebolla picada, el pimiento rojo en tiras y la picada de ajo y perejil hasta que estén tiernos. Añade el tomate doble concentrado y mezcla. Incorpora los calamares troceados y cocina unos minutos. Agrega el arroz marinera ultracongelado y mezcla bien para que se impregne del sofrito. Vierte el caldo de marisco con sofrito, añade el sazonador con azafrán y cocina a fuego medio-alto. Cuando falten 5 minutos, añade las gambas salteadas, mejillones, almejas y remueve con cuidado. Cocina hasta que el arroz esté en su punto y el caldo se haya absorbido. Deja reposar 5 minutos antes de servir.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ingredient</th>\n",
              "      <th>required_qty</th>\n",
              "      <th>required_unit</th>\n",
              "      <th>requirement_source</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>unit_size</th>\n",
              "      <th>size_format</th>\n",
              "      <th>price_unit</th>\n",
              "      <th>units_to_buy</th>\n",
              "      <th>purchase_cost_eur</th>\n",
              "      <th>escandallo_cost_eur</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arroz</td>\n",
              "      <td>0.32</td>\n",
              "      <td>kg</td>\n",
              "      <td>arroz</td>\n",
              "      <td>12782.0</td>\n",
              "      <td>Arroz marinera Hacendado ultracongelado</td>\n",
              "      <td>0.350</td>\n",
              "      <td>kg</td>\n",
              "      <td>2.20</td>\n",
              "      <td>1</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.011429</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>caldo de marisco</td>\n",
              "      <td>1.00</td>\n",
              "      <td>l</td>\n",
              "      <td>caldo de marisco</td>\n",
              "      <td>7021.0</td>\n",
              "      <td>Caldo de marisco o fideuá para paella Hacendad...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>l</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gambas</td>\n",
              "      <td>1.00</td>\n",
              "      <td>ud</td>\n",
              "      <td>fallback</td>\n",
              "      <td>35900.0</td>\n",
              "      <td>Salteado de gambas, espárragos verdes, ajos ti...</td>\n",
              "      <td>0.450</td>\n",
              "      <td>kg</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1</td>\n",
              "      <td>2.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unidad no comparable, compra minima 1 unidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mejillones</td>\n",
              "      <td>1.00</td>\n",
              "      <td>ud</td>\n",
              "      <td>fallback</td>\n",
              "      <td>18602.0</td>\n",
              "      <td>Mejillones en escabeche Hacendado medianos</td>\n",
              "      <td>0.111</td>\n",
              "      <td>kg</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1</td>\n",
              "      <td>2.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unidad no comparable, compra minima 1 unidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>calamares</td>\n",
              "      <td>1.00</td>\n",
              "      <td>ud</td>\n",
              "      <td>fallback</td>\n",
              "      <td>24242.0</td>\n",
              "      <td>Calamar troceado limpio Hacendado congelado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>kg</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1</td>\n",
              "      <td>6.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unidad no comparable, compra minima 1 unidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>almejas</td>\n",
              "      <td>1.00</td>\n",
              "      <td>ud</td>\n",
              "      <td>fallback</td>\n",
              "      <td>18554.0</td>\n",
              "      <td>Concha fina al natural Hacendado</td>\n",
              "      <td>0.090</td>\n",
              "      <td>kg</td>\n",
              "      <td>1.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unidad no comparable, compra minima 1 unidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tomate</td>\n",
              "      <td>0.20</td>\n",
              "      <td>kg</td>\n",
              "      <td>tomate</td>\n",
              "      <td>16074.0</td>\n",
              "      <td>Tomate doble concentrado Hacendado extra</td>\n",
              "      <td>0.170</td>\n",
              "      <td>kg</td>\n",
              "      <td>1.05</td>\n",
              "      <td>2</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1.235294</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>pimiento rojo</td>\n",
              "      <td>0.15</td>\n",
              "      <td>kg</td>\n",
              "      <td>pimiento</td>\n",
              "      <td>69310.0</td>\n",
              "      <td>Pimiento rojo</td>\n",
              "      <td>0.270</td>\n",
              "      <td>kg</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cebolla</td>\n",
              "      <td>0.15</td>\n",
              "      <td>kg</td>\n",
              "      <td>cebolla</td>\n",
              "      <td>69079.0</td>\n",
              "      <td>Cebollas</td>\n",
              "      <td>2.000</td>\n",
              "      <td>kg</td>\n",
              "      <td>3.90</td>\n",
              "      <td>1</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.292500</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ajo</td>\n",
              "      <td>0.02</td>\n",
              "      <td>kg</td>\n",
              "      <td>ajo</td>\n",
              "      <td>40475.0</td>\n",
              "      <td>Picada de ajo y perejil</td>\n",
              "      <td>0.100</td>\n",
              "      <td>kg</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>aceite de oliva</td>\n",
              "      <td>0.06</td>\n",
              "      <td>l</td>\n",
              "      <td>aceite de oliva</td>\n",
              "      <td>4641.0</td>\n",
              "      <td>Aceite de oliva 1º Hacendado</td>\n",
              "      <td>5.000</td>\n",
              "      <td>l</td>\n",
              "      <td>20.85</td>\n",
              "      <td>1</td>\n",
              "      <td>20.85</td>\n",
              "      <td>0.250200</td>\n",
              "      <td>OK unidades comparables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>azafran</td>\n",
              "      <td>1.00</td>\n",
              "      <td>ud</td>\n",
              "      <td>fallback</td>\n",
              "      <td>34702.0</td>\n",
              "      <td>Sazonador para paella con azafrán Hacendado</td>\n",
              "      <td>0.020</td>\n",
              "      <td>kg</td>\n",
              "      <td>1.55</td>\n",
              "      <td>1</td>\n",
              "      <td>1.55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unidad no comparable, compra minima 1 unidad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ingredient  required_qty required_unit requirement_source  \\\n",
              "0              arroz          0.32            kg              arroz   \n",
              "1   caldo de marisco          1.00             l   caldo de marisco   \n",
              "2             gambas          1.00            ud           fallback   \n",
              "3         mejillones          1.00            ud           fallback   \n",
              "4          calamares          1.00            ud           fallback   \n",
              "5            almejas          1.00            ud           fallback   \n",
              "6             tomate          0.20            kg             tomate   \n",
              "7      pimiento rojo          0.15            kg           pimiento   \n",
              "8            cebolla          0.15            kg            cebolla   \n",
              "9                ajo          0.02            kg                ajo   \n",
              "10   aceite de oliva          0.06             l    aceite de oliva   \n",
              "11           azafran          1.00            ud           fallback   \n",
              "\n",
              "    product_id                                       product_name  unit_size  \\\n",
              "0      12782.0            Arroz marinera Hacendado ultracongelado      0.350   \n",
              "1       7021.0  Caldo de marisco o fideuá para paella Hacendad...      1.000   \n",
              "2      35900.0  Salteado de gambas, espárragos verdes, ajos ti...      0.450   \n",
              "3      18602.0         Mejillones en escabeche Hacendado medianos      0.111   \n",
              "4      24242.0        Calamar troceado limpio Hacendado congelado        NaN   \n",
              "5      18554.0                   Concha fina al natural Hacendado      0.090   \n",
              "6      16074.0           Tomate doble concentrado Hacendado extra      0.170   \n",
              "7      69310.0                                      Pimiento rojo      0.270   \n",
              "8      69079.0                                           Cebollas      2.000   \n",
              "9      40475.0                            Picada de ajo y perejil      0.100   \n",
              "10      4641.0                       Aceite de oliva 1º Hacendado      5.000   \n",
              "11     34702.0        Sazonador para paella con azafrán Hacendado      0.020   \n",
              "\n",
              "   size_format  price_unit  units_to_buy  purchase_cost_eur  \\\n",
              "0           kg        2.20             1               2.20   \n",
              "1            l        2.00             1               2.00   \n",
              "2           kg        2.90             1               2.90   \n",
              "3           kg        2.80             1               2.80   \n",
              "4           kg        6.00             1               6.00   \n",
              "5           kg        1.90             1               1.90   \n",
              "6           kg        1.05             2               2.10   \n",
              "7           kg        0.78             1               0.78   \n",
              "8           kg        3.90             1               3.90   \n",
              "9           kg        1.50             1               1.50   \n",
              "10           l       20.85             1              20.85   \n",
              "11          kg        1.55             1               1.55   \n",
              "\n",
              "    escandallo_cost_eur                                         notes  \n",
              "0              2.011429                       OK unidades comparables  \n",
              "1              2.000000                       OK unidades comparables  \n",
              "2                   NaN  Unidad no comparable, compra minima 1 unidad  \n",
              "3                   NaN  Unidad no comparable, compra minima 1 unidad  \n",
              "4                   NaN  Unidad no comparable, compra minima 1 unidad  \n",
              "5                   NaN  Unidad no comparable, compra minima 1 unidad  \n",
              "6              1.235294                       OK unidades comparables  \n",
              "7              0.433333                       OK unidades comparables  \n",
              "8              0.292500                       OK unidades comparables  \n",
              "9              0.300000                       OK unidades comparables  \n",
              "10             0.250200                       OK unidades comparables  \n",
              "11                  NaN  Unidad no comparable, compra minima 1 unidad  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = 'Dime la receta para paella de marisco para 4 personas'\n",
        "result = ask_agent(\n",
        "    question,\n",
        "    top_k=35,\n",
        "    retrieval_mode='hybrid',\n",
        "    alpha=0.65,\n",
        "    recipe_mode='auto',\n",
        "    use_ingredient_tool=True,\n",
        "    candidates_per_ingredient=12,\n",
        ")\n",
        "print(result['answer'])\n",
        "result['cost_plan'].head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notas\n",
        "- Si cambias el Excel, vuelve a ejecutar la celda de `chunks` y luego `ensure_embeddings(..., force_rebuild=True)`.\n",
        "- Puedes bajar coste usando menos `top_k` o cambiando a un modelo chat mas pequeno.\n",
        "- Puedes guardar respuestas historicas en CSV si quieres trazabilidad de preguntas/respuestas.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
